from numba import cuda
import numpy
from numpy import random
import numpy


@cuda.jit
def my_kernel(matriz_a, matriz_b, matriz_c, width):

  i = cuda.threadIdx.x 
  j = cuda.blockIdx.x

  x = 0
  soma = 0
  if i < width and j < width:
    while( x < width):
      soma = soma + matriz_a[i][x] * matriz_b[x][j]
      x += 1
      matriz_c[i][j] = soma
       




matriz_a = [ [2, 3], [1, 0] ]
matriz_b = [ [3, 1], [2, 4] ]
matriz_c =  [ [0, 0], [0, 0] ]

a = numpy.array(matriz_a)
b = numpy.array(matriz_b)
c = numpy.array(matriz_c)

# números de threads por bloco
threads_per_block = 2

# número de blocos por grid
blocks_per_grid = (16 + (threads_per_block-1))

my_kernel[blocks_per_grid, threads_per_block](a, b, c, 2)

print("UNIFAGOC - CENTRO UNIVERSITARIO GOVERNADOR OZANAM COELHO\n\nMatheus Jose Ferreira Toledo.\n\n\nO objetivo do programa é realizar a multiplicação de duas matrizes em GPU,\ncomputando dessa maneira, paralelamente a multiplicação")

print( "\n\nMatriz resultante esperada pela funcao matmul: \n" , numpy.matmul(matriz_a, matriz_b) )

print ("\n\n")

print("Matriz resultante obtida pela computação em GPU: \n" , c)
